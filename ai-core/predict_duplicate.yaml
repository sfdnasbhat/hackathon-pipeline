apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: data-pipeline # executable id, must be unique across all your workflows (YAML files)
  annotations:
    scenarios.ai.sap.com/description: "Learning how to ingest data to workflows"
    scenarios.ai.sap.com/name: "predictor(Tutorial)" # Scenario name should be the use case
    executables.ai.sap.com/description: "inference with live data"
    executables.ai.sap.com/name: "training" # Executable name should describe the workflow in the use case
    artifacts.ai.sap.com/housedataset.kind: "dataset" # Helps in suggesting the kind of inputs that can be attached.
  labels:
    scenarios.ai.sap.com/id: "learning-datalines"
    ai.sap.com/version: "1.0"
spec:
  #imagePullSecrets:
   # - name: dckr_pat_iOZpHspmBcRxodGLlYf5__ogR6Y# your docker registry secret
    inputs:
      artifacts:  # placeholder for cloud storage attachements
        - name: newdata # a name for the placeholder
          path: /app/data/ # where to copy in the Dataset in the Docker image
